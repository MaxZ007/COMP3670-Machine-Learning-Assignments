{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP3670/6670 Programming Assignment 2 - Clustering, Linear Regression and Gradient Descent\n",
    "---\n",
    "\n",
    "**Enter Your Student ID:**\n",
    "\n",
    "**Your Name:**\n",
    "    \n",
    "**Deadline:** 23:59pm, 19 September, 2021\n",
    "\n",
    "**Submit:** Write your answers in this file, and submit a single Jupyter Notebook file (.ipynb) on Wattle. Rename this file with your student number as 'uXXXXXXX.ipynb'. Note: you don't need to submit the .png or .npy files. \n",
    "\n",
    "**Enter Discussion Partner IDs Below:**\n",
    "You could add more IDs with the same markdown format above.\n",
    "\n",
    "**Programming Section**:\n",
    "- 1: 30%\n",
    "- 2: 40%\n",
    "- 3: 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: Clustering\n",
    "-----------\n",
    "These programming exercises will focus on K-means clustering. \n",
    "\n",
    "If you're unsure of how k-means works, read this very helpful and freely available online breakdown from Stanford's CS221 course; https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "\n",
    "This assignment requires you to loosely interpret how k-means is a specific case of a more general algorithm named Expectation Maximisation. This is explained toward the end of the above article.\n",
    "\n",
    "First, lets loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.load(\"./data_clustering.npy\")\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is a special, simple case of the Expectation Maximisation (EM) algorithm.\n",
    "\n",
    "This simplified EM (k-means), is divided into two steps.\n",
    "\n",
    "The **E-Step**, where for every sample in your dataset you find which \"centroid\" that datapoint is closest to that sample, and record that information.\n",
    "\n",
    "The **M-Step**, where you move each \"centroid\" to the center of the samples which were found to be closest to it in the **E-Step**.\n",
    "\n",
    "Each *centroid* is simply an estimated mean of a cluster. If you have $1$ centroid, then this centroid will become the mean of all your data.\n",
    "\n",
    "Centroids are initially random values, and the k-means algorithm attempts to modify them so that each one represents the center of a cluster.\n",
    "\n",
    "We have implemented a centroids initialization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55638768  1.19083041]\n",
      " [ 0.99468733 -0.63105385]\n",
      " [-0.80861347 -0.47487527]\n",
      " [ 0.83443335  0.7038998 ]]\n"
     ]
    }
   ],
   "source": [
    "def initialise_parameters(m, X):\n",
    "    C = X[np.random.choice(X.shape[0], m)]\n",
    "    return C\n",
    "\n",
    "C = initialise_parameters(4, X)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement K-Means algorithm.\n",
    "\n",
    "---\n",
    "   **TASK 1.1:** Create a function $E\\_step(C, X) = L$, where $L$ is a matrix of the same dimension of the dataset $X$.\n",
    "   \n",
    "   This function is is the **E-Step** (or \"assignment step\") mentioned earlier.\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** \n",
    "- https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "- https://en.wikipedia.org/wiki/K-means_clustering#Standard_algorithm\n",
    "- Each row of $L$ is a centroid taken from $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(C, X):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "L = E_step(C, X)\n",
    "plt.scatter(L[:, 0], L[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1.2:** Create a function $M\\_step(C, X, L) = C$ which returns $C$ modified so that each centroid in $C$ is placed in the middle of the samples assigned to it. This is the **M-Step**.\n",
    "\n",
    "In other words, make each centroid in $C$ the average of all the samples which were found to be closest to it during the **E-step**. This is also called the \"update step\" for K-means.\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_equal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(C, X, L):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "print('Before:')\n",
    "print(C)\n",
    "print('\\nAfter:')\n",
    "new_C = M_step(C, X, L)\n",
    "print(new_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1.3:** Implement $kmeans(X, m, i) = C, L$ which takes a dataset $X$ (of any dimension) and a scalar value $m$, and uses the previous 3 functions you wrote to:\n",
    "- generate $m$ centroids.\n",
    "- iterate between the E and M steps $i$ times (ie, it iterates $i$ times) to classify the $m$ clusters.\n",
    "\n",
    "...and then returns:\n",
    "- $C$, the centers of the $m$ clusters after $i$ iterations.\n",
    "- $L$, the labels (centroid values) assigned to each sample in the dataset after $i$ iterations.\n",
    "---\n",
    "**HINT:** Using initialise_parameters to initial centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, m, i):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "#CODE TO DISPLAY YOUR RESULTS. DO NOT MODIFY.\n",
    "C_final, L_final = kmeans(X, 4, 10)\n",
    "print('Initial Parameters:')\n",
    "print(C)\n",
    "print('\\nFinal Parameters:')\n",
    "print(C_final)\n",
    "\n",
    "def allocator(X, L, c):\n",
    "    cluster = []\n",
    "    for i in range(L.shape[0]):\n",
    "        if np.array_equal(L[i, :], c):\n",
    "            cluster.append(X[i, :])\n",
    "    return np.asarray(cluster)\n",
    "\n",
    "colours = ['r', 'g', 'b', 'y']\n",
    "for i in range(4):\n",
    "    cluster = allocator(X, L_final, C_final[i, :])\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], c=colours[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer should like this, maybe with different colors:\n",
    "![image](./cluster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**TASK 1.4:** Explain how do you find the number of centroids\n",
    "\n",
    "---\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Linear Regression and Gradient Descent\n",
    "---\n",
    "\n",
    "For exercise 2, we're going to implement multiple target **batch** linear regression with mean squared loss,\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{2 m} \\sum_{i = 0}^{m} \\mid \\mid x_i\\theta - y_i \\mid \\mid^2$$.\n",
    "\n",
    "For the following questions:\n",
    "- $x \\in \\mathbb{R}^{m}$ is the vector directly representing input features from the provided dataset. Each row of $x$ is a single training example.\n",
    "- $X \\in \\mathbb{R}^{m \\times n}$ is the constructed feature matrix (e.g. polynomial features) used for learning. Each row of $X$ is a single training example.\n",
    "- $\\theta$ is our parameters. In the linear regression you've seen thus far, this is a vector. However, as we're doing multiple target linear regression, $\\theta$ will be a matrix.\n",
    "- $y \\in \\mathbb{R}^{m}$ is a matrix of the target values we're trying to estimate for each row of $X$. Each row $i$ of $X$ corresponds to row $i$ of $Y$.\n",
    "- $m$ is the number of training examples.\n",
    "- $n$ is the dimensionality of one training example.\n",
    "\n",
    "Typically when people think of linear regression, they think of a mapping from $\\mathbb{R}^n \\rightarrow \\mathbb{R}$, where they're trying to predict a single scalar value.\n",
    "\n",
    "---\n",
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = np.load(\"./data_regression.npy\")\n",
    "plt.plot(x_train,y_train,'o') ## YOUR CODE HERE\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(\"Training data\")\n",
    "plt.ylim([-1,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that it is not a good idea to perform linear regression directly on the input feature `x`. We need to add polynomial features. Lets construct an appropriate feature vector.\n",
    "\n",
    "---\n",
    "**Task 2.1**:  Complete the `get_polynomial_features` function with the following specifications.\n",
    "* Input1: an array `x` of shape $(m,1)$.\n",
    "* Input2: `degree` of the polynomial (integer greater than or equal to one).\n",
    "* Output: matrix of shape $(m,degree+1)$ consisting of horizontally concatenated polynomial terms.\n",
    "* Output: the first column of output matrix should be all ones.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_features(x,degree=5):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "# get polynomial features\n",
    "X_train = get_polynomial_features(x_train,degree=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement gradient descent to find the optimal $\\theta$.\n",
    "\n",
    "\n",
    "---\n",
    "**TASK 2.2:** Write a function $initialise\\_parameters(n) = \\theta$, where $\\theta$ is the parameters we will use for linear regression $X\\theta = Y$ for $X \\in \\mathbb{R}^{m \\times n}, Y \\in \\mathbb{R}^{m}$.\n",
    "\n",
    "The values of $\\theta$ should be randomly generated. You will be judged on whether the matrix $\\theta$ is correctly constructed for this problem.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** $\\theta$ should be an array of length $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialise_parameters(n):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# initialize theta\n",
    "theta = initialise_parameters(X_train.shape[1])\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**TASK 2.3:** Implement a function $ms\\_error(X, \\theta, y) = err$, which gives the **mean** squared error over all $m$ training examples.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_error(X, theta, y):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "print(ms_error(X_train, theta, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 2.4:** Implement $grad(X, \\theta, Y) = g$, a function that returns the average gradient ($\\partial \\mathcal{L}/\\partial {\\theta}$) across all the training examples $x_i \\in \\mathbb{R}^{1 \\times n}$.\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** \n",
    "- The gradient should be an array with same length as $\\theta$.\n",
    "- https://www.sharpsightlabs.com/blog/numpy-sum/\n",
    "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.multiply.html\n",
    "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X, theta, Y):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "print(grad(X_train, theta, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 2.5:** Implement $batch\\_descent(X, Y, iterations, learning\\_rate) = \\theta, L$, a function which implements batch gradient descent returning $\\theta$ (parameters which estimate $Y$ from $X$), and $L$.\n",
    "\n",
    "$iterations$ is the number of gradient descent iterations to be performed.\n",
    "\n",
    "$learning\\_rate$ is, of course, the learning rate.\n",
    "\n",
    "$L$ is a matrix recording the mean squared error at every iteration of gradient descent. It will be an array of length $iterations$.\n",
    "\n",
    "You should use the functions you completed earlier to complete this. \n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** \n",
    "- Remember, the point of gradient descent is to minimise the loss function. \n",
    "- It does this by taking \"steps\". The gradient always points in the steepest direction uphill, so by stepping in the opposite direction of the gradient we move toward the value of $\\theta$ that minimises the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_descent(X, Y, iterations, learning_rate):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "#REPORTING CODE. YOU MAY NEED TO MODIFY THE LEARNING RATE OR NUMBER OF ITERATIONS\n",
    "new_theta, L = batch_descent(X_train, y_train, 5000, 0.5)\n",
    "plt.plot(L)\n",
    "plt.title('Mean Squared Error vs Iterations')\n",
    "plt.show()\n",
    "print('New Theta: \\n', new_theta)\n",
    "print('\\nFinal Mean Squared Error: \\n', ms_error(X_train, new_theta, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Regularization and Model Selection\n",
    "---\n",
    "\n",
    "In task 2, we focussed on using gradient descent to do linear regression with a polynomial of degree 5.\n",
    "\n",
    "Next, we would try to select a model that gives best performance on the val set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 3.1**:  Visualize the prediction curves for different choice of degree polynomial features, by completing the code below. \n",
    "\n",
    "- You can use the closed form solution or gradient descent for computing $\\theta$.\n",
    "- Compute the predictions on val data using `x_val` and computed $\\theta$.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_theta(X,y):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "def get_prediction(X,theta):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "for degree in range(1,10):\n",
    "    # prepare train/val data\n",
    "    X_train = get_polynomial_features(x_train,degree=degree)\n",
    "    x_val = np.linspace(-0.7, 0.8, x_val.shape[0])\n",
    "    X_val = get_polynomial_features(x_val,degree=degree)\n",
    "    \n",
    "    # get theta\n",
    "    theta = get_theta(X_train,y_train)\n",
    "    \n",
    "    # compute predictions on train/val set\n",
    "    pred_y_train = get_prediction(X_train,theta)\n",
    "    pred_y_val = get_prediction(X_val,theta)\n",
    "    \n",
    "    # plot results\n",
    "    plt.plot(x_train,y_train,'o',label='train')\n",
    "    plt.plot(x_val,pred_y_val,label='val')\n",
    "    plt.legend()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(\"polynomial degree: {}\".format(degree))\n",
    "    plt.ylim([-1,3])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 2.2**:  Draw the train, val loss curve for different degree polynomials by completing the following code.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = np.load(\"./data_regression.npy\")\n",
    "# store train/val loss values\n",
    "train_loss,val_loss = [],[]\n",
    "\n",
    "for degree in range(1,10):\n",
    "    # prepare train/val data\n",
    "    X_train =     # YOUR CODE HERE\n",
    "    X_val =     # YOUR CODE HERE\n",
    "\n",
    "    # get theta\n",
    "    theta = get_theta(# YOUR CODE HERE)\n",
    "    \n",
    "    # compute train/val losses\n",
    "    train_loss.append(# YOUR CODE HERE)\n",
    "    val_loss.append(# YOUR CODE HERE)\n",
    "    \n",
    "\n",
    "plt.plot(range(1,10),train_loss,'-o',label='train loss')\n",
    "plt.plot(range(1,10),val_loss,'-o',label='val loss')\n",
    "plt.xticks(range(1,10))\n",
    "plt.legend()\n",
    "plt.title('Train/Val Loss vs polynomial order')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "**Task 2.3**:  What is the best choice for degree of polynomial features suitable for this problem?\n",
    "\n",
    "---\n",
    "\n",
    "**Answer**: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
